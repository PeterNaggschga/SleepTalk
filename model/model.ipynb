{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SleepTalk\n",
    "\n",
    "## Categories:\n",
    "\n",
    "| Category       | Label  |\n",
    "|----------------|--------|\n",
    "| Talk           | SPEECH |\n",
    "| Snoring        | SNORE  |\n",
    "| Sighs          | SIGH   |\n",
    "| Farts          | FART   |\n",
    "| Loud breathing | BREATH |\n",
    "| Cough          | COUGH  |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T16:07:57.438952Z",
     "start_time": "2024-07-28T16:07:57.436304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define classes TODO: define depending on training data\n",
    "\n",
    "classes = [\"SPEECH\", \"SNORE\", \"SIGH\", \"FART\", \"BREATH\", \"COUGH\"]\n",
    "no_class = \"NONE\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training data collection\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T15:54:01.903192Z",
     "start_time": "2024-07-28T15:49:56.321819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "google_data_dir = \"google\"\n",
    "\n",
    "\n",
    "# download google training embeddings\n",
    "if os.path.exists(google_data_dir):\n",
    "    shutil.rmtree(google_data_dir)\n",
    "    \n",
    "print(\"Downloading training features...\")\n",
    "with urllib.request.urlopen(\"https://storage.googleapis.com/eu_audioset/youtube_corpus/v1/features/features.tar.gz\") as response, tarfile.open(fileobj=response, mode='r|gz') as targz:\n",
    "    targz.extractall(filter='tar')\n",
    "    os.rename(\"audioset_v1_embeddings\", google_data_dir)\n",
    "\n",
    "print(\"done\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "google_label_file = f\"{google_data_dir}/labels.csv\"\n",
    "if not os.path.exists(google_label_file):\n",
    "    urllib.request.urlretrieve(\"https://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\", google_label_file)\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T16:51:10.523862Z",
     "start_time": "2024-07-28T16:51:10.520179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synonyms = {\n",
    "    classes[0]: [\"Speech\", \"Shout\", \"Whispering\"], # SPEECH\n",
    "    classes[1]: [\"Snoring\"], # SNORE\n",
    "    classes[2]: [\"Sigh\", \"Groan\", \"Grunt\"], # SIGH\n",
    "    classes[3]: [\"Stomach rumble\", \"Fart\"], # FART\n",
    "    classes[4]: [\"Yawn\", \"Sniff\", \"Wheeze\", \"Gasp\", \"Pant\", \"Snort\"], # BREATH\n",
    "    classes[5]: [\"Cough\", \"Sneeze\"], # COUGH\n",
    "    no_class: [\"Chewing, mastication\", \"Biting\", \"Burping, eructation\", \"Bang\", \"Slap, smack\", \"Whack, thwack\", \"Smash, crash\", \"Knock\", \"Tap\", \"Flap\", \"Vehicle\", \"Alarm\", \"Door\", \"Thunderstorm\", \"Wind\", \"Water\", \"Noise\"]\n",
    "}\n",
    "\n",
    "switched_synonyms = {}\n",
    "for (key, entry) in synonyms.items():\n",
    "    for synonym in entry:\n",
    "        switched_synonyms[synonym] = key\n",
    "\n",
    "synonyms = switched_synonyms"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:10:29.086822Z",
     "start_time": "2024-07-28T20:10:29.083824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "label_to_class = {}\n",
    "with open(google_label_file, newline='') as label_file:\n",
    "    reader = csv.reader(label_file)\n",
    "    for row in filter(lambda r: r[2] in synonyms.keys(), reader):\n",
    "        label_to_class[int(row[0])] = synonyms[row[2]]\n"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:34:16.950604Z",
     "start_time": "2024-07-28T20:34:16.940154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_sequence_examples(filename):\n",
    "    iterator = tf.compat.v1.io.tf_record_iterator(path=filename)\n",
    "    \n",
    "    result = []\n",
    "    for string_record in iterator:\n",
    "        example = tf.train.SequenceExample()\n",
    "        example.ParseFromString(string_record)\n",
    "        result.append(example)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "google_embeddings_class = []\n",
    "google_labels_class = []\n",
    "google_embeddings_no_class = []\n",
    "google_labels_no_class = []\n",
    "\n",
    "\n",
    "\n",
    "balanced_train_dir = f\"{google_data_dir}/bal_train\"\n",
    "filenames = [f\"{balanced_train_dir}/{file}\" for file in os.listdir(balanced_train_dir)]\n",
    "\n",
    "for filename in filenames:\n",
    "    examples = get_sequence_examples(filename)\n",
    "    print(examples)\n",
    "    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[context {\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"WPvMJ0LMTtY\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 210\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 137\n",
      "        value: 253\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 220\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature_lists {\n",
      "  feature_list {\n",
      "    key: \"audio_embedding\"\n",
      "    value {\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\255OhF\\215N\\251\\334\\247\\210\\321rS\\235\\212y\\262\\261Q\\216\\271\\\"\\254j\\305Is\\341\\311\\265#\\000_[\\205\\256\\260h\\016\\306S*rgP\\251\\225\\000\\227vq\\260N`\\345\\246Jc\\375\\024N\\243\\021<zX\\241O|e.\\246\\252\\273{\\\\\\252\\377\\214\\240\\205a\\327sjt\\216yk\\212\\222\\320\\304\\205de\\226\\000\\317\\010Xc\\246G\\267<9f5\\206\\244v\\355\\221\\241\\244\\306\\225\\024\\306\\241\\300c\\3746\\241\\007&\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\241R`Bt/\\272\\335\\243k\\351jW\\203\\236r\\256\\215[\\243\\336#\\303p\\264-z\\322\\343\\234\\020\\000ha\\177\\240\\274h\\000\\303/,\\203?V\\271\\211\\000\\210n:\\246\\204r\\330\\265(f\\324+@\\246\\021N\\220\\\\vfnZKd\\260\\224\\205m\\247\\377\\247\\215wN\\251\\212XA\\221w*\\214z\\252\\243\\300ZN|U\\315\\000\\\\D\\243\\200\\304z8SKs\\350t\\347\\226c\\300\\377\\305@\\337\\240\\201q\\260N\\217\\0369\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\236DwL\\212\\036\\257\\306\\241|\\332Yj\\177\\246a\\301\\220}\\265\\317C\\272_\\240;~\\300\\270\\253@\\rpe\\205\\260\\247y\\027\\242NCj4f\\255}\\t{ud\\263ie\\307\\246=d\\247Y|\\235\\003d\\243|{g\\205dZa\\241\\305\\206\\215\\221\\377\\263\\235eU\\252\\230QAn\\327G\\200o\\247\\262\\261f~\\2038\\252\\000bJ\\260\\202\\251`EO}o\\3549\\270\\230U\\215\\377\\274N\\317\\221\\212|\\2379\\2333G\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\234I{:{ \\254\\302\\234x\\335mm\\212\\224]\\242t]\\254\\324\\033\\277k\\2279\\234\\310\\262\\274!\\t_X\\211\\306\\255P\\001\\3037.v;I\\343\\230\\016fyh\\225}{\\306\\247Bk\\255\\036z\\215\\000m\\261{oVsZQa\\311\\317\\202\\177\\235\\375\\234\\200{g\\225\\2325J^}D\\241c\\207\\242\\352:\\223\\206\\\"\\320\\021\\212\\034{w\\252^Cg\\200y\\272u\\341\\207v\\262\\377\\326*\\377\\230\\200P\\2204\\301\\033V\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\243U\\210/|P\\256\\337\\267x\\335u]\\211\\221n\\310\\227Y\\226\\277\\030\\254p\\266R\\241\\321\\343\\246\\\"\\000vtq\\233\\274c*tx\\025_Pq\\273\\216(seo\\245!\\220\\272\\273-w\\321Eep\\017{\\200q\\225-tcW\\221\\260\\377\\214\\271\\271\\3773\\235\\207~\\350i\\246uv\\233\\256\\244\\177\\301\\314\\244\\246ey\\\"\\266)o6\\256\\222\\306B[\\237b\\201\\274\\216\\200\\266\\236\\312\\252\\261&\\331\\340\\377u\\211$\\206\\000;\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\246PlE\\2125\\237\\332\\237\\202\\345oc\\205\\254V\\270\\235k\\231\\313*\\277X\\303K\\210\\326\\305\\270(\\000\\201Wy\\257\\275m\\035\\322J)dG^\\250\\203\\000zJM\\255OY\\303\\206.M\\333:b\\217\\000I\\307f{f\\200\\206F}\\302\\255\\250\\212\\226\\377\\222\\256\\217T\\355jfbo\\222no\\224\\272\\310\\256{l\\242.\\300\\004h/\\237o\\252WHS;]\\363x\\244\\257q\\250\\375\\231$\\241\\304\\327`\\273Lw\\036\\033\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\265MtP\\220S\\260\\314\\257~\\307Sk\\211\\216r\\243\\227`\\217\\270+\\223Q\\272N\\204\\333\\240\\251B\\000et\\201\\262\\274|I\\251N-nkY\\237\\202&u`y\\252Sl\\273\\246Rt\\302V{\\204\\000Y\\212t\\222b|e6\\221\\255\\310\\221\\210\\251\\377\\217_g\\201\\261@avi\\177gju\\270\\272\\206Z}\\2528\\254>~d\\230`\\207;_~j\\247\\2326\\341\\264\\306\\203\\312\\212\\032\\311\\325\\273c\\225B\\245\\032b\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\263UnF\\202`\\334\\354\\254b\\317]e\\204\\177\\217\\223\\231P\\246\\270\\016\\262a\\2537\\213\\377\\272\\240)\\000a\\202m\\251\\247i\\030\\226#-\\235]S\\256m8e\\236S\\251|m\\335\\264:\\225\\377=H\\246\\000R]e\\220\\200}iE\\231\\255\\227\\250\\203\\256\\366|Xp\\234\\2418|_vE\\\\\\245\\202\\265\\230\\253f~\\2476\\257:L?\\333`\\301Q;m\\215\\223\\214\\234\\351\\207\\242k\\236q3\\330\\357fk\\366A\\312\\033d\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\266kb?y{\\353\\367\\270b\\276ZL\\234\\201\\253\\217\\311\\037\\237\\333\\000\\262s\\300>t\\377\\253\\2448\\000M\\200{\\307\\244w#\\243 %\\227hH}|\\027\\230\\212s\\262fu\\377\\312B\\265\\377\\010\\036\\234\\036F\\014m\\255\\233\\255W\\027\\317\\230\\202\\210[\\302\\377\\240Uu\\250\\232\\000}W\\241.^\\314\\236\\327\\233V~_\\2410\\270S2\\217\\371G\\347*\\'Oi\\272\\225\\253\\377\\310\\352]YBJ\\276\\377tS\\377\\021\\377\\007\\204\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\254eYBz\\206\\335\\377\\267i\\315\\2145|\\201\\232\\250\\306.\\252\\302\\000\\313v\\311:q\\377\\273\\246#\\000cg\\203\\242wu\\000\\303\\027\\031\\300\\\\Q\\221e\\017\\226\\213Y\\247nx\\367\\215(\\205\\377\\027\\024\\347 (EE\\246\\230\\273\\244 \\242\\256^\\232\\213\\263\\363\\240zo\\205\\215\\036\\204\\211\\201Nbn\\242\\300\\266j\\212>\\274-\\243;h\\177\\333}\\310X\\000j}\\242\\243\\264\\271\\345\\221\\222|fN\\202\\276qU\\377\\022\\3252(\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", context {\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"WP7F7PQb454\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 360\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 376\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 370\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature_lists {\n",
      "  feature_list {\n",
      "    key: \"audio_embedding\"\n",
      "    value {\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\037]z\\000\\221\\264cs\\333\\251-\\337\\\"\\355\\272\\351\\215?R\\247\\325\\224\\2008\\000\\3773\\377\\340\\232\\247\\000\\200\\236cd\\031\\235\\033\\036j\\326N\\000\\266\\211\\377\\377\\274\\0000\\211\\377\\000\\312_\\320\\000\\000}6\\370\\303\\225\\221\\325K\\000\\377\\000V\\023\\000\\000\\241j\\024u\\201ROA\\227\\307\\000a\\237!=\\177\\257V6A\\214Q\\000\\377\\377\\377\\213\\034U\\000\\000\\331\\332\\267\\000\\372\\0000\\331D\\377\\352\\000\\314\\234\\341W\\377\\010\\003s8\\377\\350\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"P}Y\\000\\230k\\265\\215\\361\\207]\\2023\\325v\\236\\377\\213N\\361\\377\\235\\373S?\\377\\257\\377\\034\\341;\\000.$l\\0072\\277=/*\\375\\241\\032\\000\\000\\377\\275\\031A3o\\377&\\377\\342\\206\\253\\0002\\227s\\3017^\\301Ve\\340\\000\\2318Q@\\246x\\000\\303\\214\\222B\\263\\265Us%\\266Dq\\314k\\377\\000\\232\\000\\000\\000AL\\3775\\351\\000\\000a\\377\\000\\343\\000\\377\\202\\000\\242\\031%\\000\\237\\272l\\033\\256\\377fe\\303x\\366X\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\026\\232P\\000\\305\\247\\260r\\277s/\\264\\\\\\372\\203\\377\\255\\247\\037\\243\\317\\246\\312A\\000\\377K\\377\\177\\207\\220\\0006\\303+\\000\\000\\276\\000:Y\\377\\215\\000(\\000\\377\\336:\\245\\007?\\377h\\345}\\177T\\000g2\\345\\305\\000\\000\\372Ju\\361\\000\\377<\\267\\000\\341\\265\\000&~m\\007o+\\202GR\\377\\234\\000\\273\\364\\323\\000\\362^i\\000\\377!\\377\\222\\276\\000\\000\\000\\377s\\370\\000\\377\\000\\000y\\207\\343u\\225\\005\\275\\331\\000\\337Q\\277\\3770\\311L\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"&\\273b\\000\\273\\273h\\177\\263\\312#\\377\\000\\375\\377\\377H\\373(o\\377y\\344f\\'\\3776\\377\\264cM\\000\\253\\377bv\\022\\337\\000QG\\377J\\000b\\000\\377\\377\\377\\000\\010\\377\\377k\\364\\377\\277\\245\\032 N\\361\\252\\235\\224\\354\\377\\240\\367>\\377(S\\026\\024K{\\032\\0000\\205chiu\\207u\\000\\215\\377\\366F\\0009\\000\\274\\000\\377\\377\\377\\377A:U(\\301\\347\\377O\\311\\000\\000[\\224\\370\\2516\\2703\\222!\\331\\000\\n\\253\\000+\\377\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\000\\377\\000\\000L\\376\\377\\257\\276?\\025\\\\\\000\\323\\360\\377\\377yC\\211\\377\\315\\377\\226\\000\\3778\\377\\000\\377F\\000\\000IC\\000\\013\\377\\000\\000\\377\\276S\\313\\000\\000\\377f\\022\\000\\000j\\377\\000\\377\\336l\\377\\000!T\\377\\335\\000\\361\\377\\022\\000\\377\\000\\336\\000\\267\\000\\377\\377\\000\\263|\\000\\377\\251\\000\\270\\3776\\377n\\246\\377\\275\\302\\000\\377\\377\\000\\000\\\"\\000\\377\\233\\377\\000\\000r\\377\\377\\226\\000U\\377\\000\\024\\377\\277\\377QF\\000\\000\\321\\204\\000\\016\\377\\302\\205v\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\000\\377\\000\\000\\016\\377\\375\\234\\254\\033\\023$\\000\\324\\366\\377\\377\\262S\\323\\377\\323\\377o\\000\\3775\\377\\000\\377s\\000\\000\\0003\\000=\\377E\\000\\211q\\233\\253\\000\\000\\377\\242\\000\\007tg\\3779\\377\\000\\246\\377\\000\\0008\\377\\377\\000\\377\\377\\304\\000\\377\\000\\377\\000\\377;\\270\\377\\000):4\\3775\\000o\\377\\000\\304n\\222\\261\\231\\013\\000\\377\\377\\000\\000\\036\\000\\377\\377\\377\\000(\\\\\\377\\377\\000\\000\\377b\\000\\255\\377\\300\\377\\342\\000=\\000\\377\\351\\000\\000\\377\\377\\267\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"(\\260A\\000\\264eah\\306\\251N\\374\\t\\351\\377\\3662\\344hT\\321\\310\\377H\\000\\377f\\377\\263^\\177\\030~\\377Q8\\000\\377\\000\\222O\\377(\\000o\\000\\357\\350\\320u\\031\\232\\377\\247\\266\\315\\223;\\000rp\\256a7R\\346\\231\\251\\377]\\377>z\\00001\\237/\\035\\201\\205\\300\\247\\235\\257\\324\\320\\214\\214\\377\\377\\024/\\251\\000\\201\\000\\377\\317\\377\\377\\000)\\024|\\346u\\276]S.\\000c\\361n\\246\\265* \\263\\002\\305\\000\\000;\\032U\\377\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\001\\367L\\000{\\337\\247\\210\\225l\\021\\244\\000\\354\\377\\377\\243\\377\\254\\205\\377^\\377`\\000\\377K\\377c\\227G\\0008\\261\\021\\000\\030\\320\\000\\000e\\377\\320\\037{\\000\\372\\377_\\000\\000\\370\\377\\003\\377\\307E\\377\\000\\000\\203\\244\\256\\235\\377\\377\\331\\255\\377\\000\\323\\000\\303H?z\\026\\000\\003\\007\\336\\2609\\000\\363|\\340\\264\\253\\377t!\\000\\377\\325\\000\\000\\265-\\374\\377\\377\\000\\000\\000\\377\\377\\377\\000 \\233\\000wZ\\377\\377}\\306\\000T\\226\\330\\000\\000\\377J\\025\\363\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"e^\\200-\\316lLG\\236\\257i\\3326\\340\\230\\266UMPNc\\251\\240<\\000\\377{\\347\\332\\227\\334{\\343\\252^\\255\\034\\221\\000\\206.\\3779\\000\\221Y\\377\\364\\035O\\000\\263\\316\\255\\236\\240\\277\\000\\000\\371\\346\\233\\250\\222\\022~\\204^\\311v\\370\\226\\211\\n\\\"\\223\\030&\\233]\\000\\204\\272W\\2453jo\\000\\347\\325q\\000\\220fr:\\377\\225\\377\\250\\000\\242\\020\\000\\3310\\2508\\226\\000\\337\\244|\\333\\204\\217\\325\\245e\\000\\377\\213\\000]*\\310\\003\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\000\\377\\000\\000T\\377\\250\\301\\267D\\010\\311\\000\\361\\377\\377\\241\\377\\000\\377\\377\\213\\377l\\000\\377%\\377Wj\\013\\000&\\277k\\000\\021\\377\\r\\016\\267\\377\\247\\000\\031\\000\\377\\337\\377\\007\\007\\377\\377\\000\\377\\326\\227\\377\\000\\002K\\377\\377[a\\377\\253:\\377\\000\\377K\\221\\000S\\332>M\\000\\262\\244\\017\\017\\031\\360 \\262\\205\\272\\377\\377\\262\\000Y\\231\\000\\000\\342\\345\\377\\377\\377\\000\\000(\\377\\376.\\000\\377\\000\\000\\377\\377\\377\\377\\231\\000%\\222\\000\\270\\000\\000\\377\\377\\377\\311\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", context {\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"WPF49m1VuMo\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 360\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 27\n",
      "        value: 28\n",
      "        value: 69\n",
      "        value: 137\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 370\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature_lists {\n",
      "  feature_list {\n",
      "    key: \"audio_embedding\"\n",
      "    value {\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\213\\377\\367\\201\\247pRH\\257(\\202Y\\311\\177,\\365A\\246X\\000\\206 9\\232\\201\\334_\\225Z\\224]\\252\\220n\\371\\305\\244k0g\\000\\312\\177\\337\\032v\\236\\002\\320\\366zm\\377\\250\\370k\\377t\\247\\377C\\211\\327\\221\\000\\231wH\\231\\355\\230\\341U\\000\\201\\243L\\000\\377\\324b\\014K\\337\\240Q\\302\\377\\000:>b\\261\\377\\256\\000\\325\\246\\373\\270\\347\\000\\321\\321b\\377\\000!\\275\\337EGU\\023\\260\\211\\266\\307\\375\\260\\000\\000\\370S\\377\\346\\311\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\273\\377\\377m\\030\\314\\244\\300\\007\\013\\306w\\336\\342\\252\\377x\\217\\241\\033\\030\\231m\\020\\274\\320\\237\\302\\000\\332\\000\\007\\343\\222\\377\\307%\\377\\377.\\240\\000\\304Rn\\021\\261u\\326P\\221\\000\\000\\266\\257J\\000g\\231o<\\324\\377K\\204\\300\\000_\\000\\202\\377\\213\\000s\\000\\224\\233\\233\\207\\000\\000L\\377\\003\\000q3l\\261\\261U+X\\377p\\375\\377\\013\\252\\000\\000\\033}=\\370\\227\\000\\000\\275\\000\\270\\377\\261\\377\\000\\000Pq\\271\\377\\377\\000j\\000D)\\000\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\315\\320\\343\\206z\\226w\\225\\007\\217\\223-\\271\\371{\\306T,z\\241j\\252\\021\\032q\\362\\305H]\\224\\\"\\217\\346\\206\\243\\265-\\206\\275fC\\313\\275\\377u\\334\\350T\\315\\377(\\000\\377y\\337\\223\\031\\020\\353\\245;<\\351\\232\\000f\\200+6\\351\\222p<\\232\\300\\352\\202\\000\\344\\254H\\000=@#T\\215!\\000\\314\\234\\213\\2062\\274b_\\360\\301\\000\\000\\247S\\365\\221\\276\\000\\330f\\272\\226b\\205\\377@`\\000\\241\\202\\377\\000\\000\\377\\375\\376\\005\\377\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\215\\361\\3626\\217\\254n`\\224jl\\222\\026\\237Y\\377DY\\260\\000\\225\\377>\\234\\204&r\\243\\3728LJ\\377BF\\260\\000\\202\\377\\000<\\000\\377\\377\\377\\020\\377\\203\\377\\200\\367\\024\\215\\226-\\374.E\\267\\202\\376\\215u\\201\\237\\206\\255\\207\\301\\2127\\377L\\244v\\371\\000\\377z\\034\\323.\\233\\350\\267\\000\\257\\\\\\000\\276}\\300\\214g\\\\\\355\\340\\037\\254\\234\\026y\\206\\377g\\251\\037\\036\\214\\'\\211\\206\\206\\036\\000\\203\\364\\000\\000\\000\\214$\\213\\000\\205\\325\\270\\004\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\332\\370\\377yB\\241\\233}\\000q\\260U\\353\\364!\\2225Z\\r\\232~\\177\\004\\302dv\\026\\337`\\000e\\267\\271T\\371\\356\\320\\325\\263\\377\\025I\\273\\224hapK\\377]\\377\\000\\377\\350\\377ri\\036\\\"\\377\\000;\\377\\260\\000\\272H7\\377G\\202x\\014\\3019\\254\\202\\000\\352\\231c\\307\\241^u\\000\\200JX\\377\\273\\310\\377\\325&\\325t*\\245\\000\\322\\236\\214\\377\\377\\377L\\264\\377\\377\\021\\031\\206\\315\\246\\244\\000\\377MU\\000\\000p\\227\\214\\000\\377\\203\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\312\\351\\377\\203H\\206\\267_\\036d\\277L\\347\\260<\\334^\\024\\221w9u\\010Aw\\316\\266\\241\\000@\\000\\245\\227\\213\\377\\332^py\\201\\r\\377\\216\\267\\371\\246\\332\\206\\377\\200\\377\\000\\377\\310\\362X\\326\\264\\377\\311I\\000\\377O3\\242\\224\\000w\\320\\267\\346~W\\241\\363v\\000\\377\\305\\000d/\\324ov\\244\\335\\035\\201u\\377\\377\\377-\\372cX\\377\\000\\304\\362=\\377\\264\\361\\000[\\255\\377\\205\\377\\303\\377\\324\\377g\\377H\\361K\\000\\303\\266y\\000\\367\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\267\\353\\377hd{\\217\\234H(\\247\\032\\377\\306\\\\\\377:Wz;\\003_;7\\262\\377\\300\\305\\000\\231\\000P\\261\\232\\377\\377r\\242\\2337\\016e\\211\\3400\\202\\303T\\367\\377k\\000\\312\\272\\247\\301|\\000\\325\\\\fC\\346\\312\\';\\034\\000w\\223\\2103R\\225\\000\\240\\224\\000\\335\\361%\\177\\034\\216N\\037\\\\\\313\\010\\213\\216\\377x\\221\\205\\201\\363\\242\\377\\013m\\377\\272\\271A~uA\\316\\377\\332[\\271\\377L\\343\\000\\330pu\\306\\000\\000\\211\\377\\000\\312\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\215\\246\\311tS\\213\\240$\\367\\311=!\\275\\222\\000\\217\\200;\\377|m\\221\\310\\0103\\377\\210\\000\\211e\\000\\025,4T\\211\\350C\\000\\004\\000\\366\\261\\377\\303k\\372\\377)\\377\\252\\377\\250\\025]\\336R\\341\\234\\0333\\377\\377(5Q\\000P\\223\\377a\\311\\000\\022A\\r\\277\\000\\377\\377M\\000\\233\\377\\377\\000\\000y\\000\\000\\204\\325g\\377|\\274\\377\\320\\270\\000\\377\\360\\377\\377\\234\\231n\\005\\350\\377\\000v\\000\\000\\000\\271\\335\\377\\224\\000\\224\\000\\26687\\377\\\\!\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\253\\260\\256<\\\\I\\177D\\275\\327-\\031`k6\\001N\\240\\377_\\245\\212\\377X\\220\\377`\\000\\347Ghs\\234\\255\\320\\327\\276\\247\\007\\000\\222\\275\\301\\377\\214&\\200\\3770\\253\\315\\3773\\0047V(y\\272o\\000\\377\\377\\225\\034\\353\\234\\302\\357\\334$\\227\\016\\026j\\241\\326\\240\\377y\\000\\037\\252\\377\\000\\234\\213\\354\\000[\\316z\\237\\346\\265\\327\\377i\\377\\000\\224\\377\\246\\266u\\206\\377\\253\\377\\354\\345~\\000\\000\\000\\306O\\377\\2742\\337\\032=\\306\\377\\000\\000l\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\232\\243\\340a\\200WC\\244\\244\\3047]\\233\\214xTF\\213\\377 \\262\\236\\277.~\\237|\\207\\366_r\\000?B\\377\\362\\267y?\\000dK\\206\\377\\\\\\026\\341\\377S\\377\\347\\377\\177\\324g\\236\\000z\\314a/\\371\\366\\241C\\213\\222\\000\\377\\377$\\2352\\2663\\300\\377`\\316o\\000\\273\\266\\376\\000\\244H\\035\\000=\\300\\377\\306\\2152\\324\\377\\004\\355?\\000\\324n\\377\\2677\\263d\\377\\375AR\\000\\000\\000\\010\\310\\221\\261\\325\\275\\\"^\\272\\306\\030<\\334\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", context {\n",
      "  feature {\n",
      "    key: \"video_id\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"WP5bmY56fc8\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"start_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 450\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 57\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"end_time_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 460\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature_lists {\n",
      "  feature_list {\n",
      "    key: \"audio_embedding\"\n",
      "    value {\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"T@Mh\\030 \\000\\232\\321\\320\\236e\\334\\340\\000\\000\\000\\207\\304\\377\\312\\000\\355a\\035\\316\\327b\\261\\2334\\374q\\362e\\377\\253g\\000\\000\\000=\\372poi\\016\\000\\234\\000~a\\344\\000\\000\\377\\033?\\377O\\000\\377\\004f\\311\\264\\250\\300\\301\\000\\377\\377\\274\\000<\\242&\\000\\267\\000\\377$Z\\233\\315\\377B\\210-\\234\\342)Q;\\225?\\313\\377\\3778\\000\\020\\333ba\\261Mb\\352\\331#\\312\\377\\377\\377\\266\\377\\377\\025\\206+$!\\377\\377\\341\\307\\000\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"`#\\245O\\241Ls\\214\\313\\246hL\\266\\204C\\000\\260l\\207\\357\\217\\312\\230\\242\\036\\233\\205F\\233oW\\222~\\351\\245\\\"}L\\273\\034\\211\\277inPqHEr@_u\\221S\\177\\211\\213\\334\\375j\\233\\311\\227\\361\\212|\\203X\\206\\336\\'\\246\\316\\252\\227\\225Uolv\\233@\\251E1\\377g\\232\\241\\225E\\343\\0009\\210[\\025x\\025I\\226\\014:ZHM\\206\\377N\\377\\210\\000\\220\\246\\230*\\377\\220\\000\\236\\022ps\\222|\\000\\226N\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"2L~%j(H\\215\\337\\233u\\253\\361\\270@\\000dz\\226\\373\\224l\\317\\231pD\\274X\\2620\\000\\272\\177\\300\\325\\205\\3317\\332Nl\\303oo\\221w(\\000\\2471n\\204\\035p\\\"+\\000\\377\\326\\231T\\377i\\362\\231\\220\\244Cs\\000\\000\\377\\244\\221S_W\\000\\260l\\364\\000\\251\\004\\000\\377\\272#a\\272\\214\\304\\000\\0028\\000\\005\\235:\\303\\024\\000l\\306\\000\\234\\364\\232\\212\\377E\\006\\343\\373\\243\\000\\377\\206\\0001\\000\\000\\000\\350\\321\\000t\\337\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"GEm)j~\\000z\\350\\233F`\\225\\3230\\034\\260\\201h\\331\\262\\'\\244\\255\\366hPDt\\223d\\375v\\336\\311NI\\264l?I\\024\\251]g$\\255c\\206M\\211\\215[\\244\\270\\362\\226\\377m\\000q\\377\\302ai\\210\\220H\\260\\000\\233Ua\\310X\\007g\\224\\364ic\\007\\321\\226\\'\\305\\274\\254r\\266\\312\\376\\325\\\"\\247k\\025\\\\\\245G\\000\\'23\\357X\\210x\\262\\377\\335\\'\\261\\326Oq\\376\\000\\000\\377\\212IE\\317/\\000\\000\\356\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"C9\\213I|K5x\\313\\227nr\\342\\306\\035\\000n\\177\\220\\321\\306\\177\\355\\230]\\241]E\\204.@\\313`\\370\\300\\231\\253K\\251\\033%`kb}W\\0006\\267\\024\\200j%E#\\320!\\244\\257r\\033\\3266\\371\\225\\201\\rH\\227/A\\377\\256\\310\\206r/<\\227\\255\\377\\000H\\206*\\377|\\213\\271\\323\\223\\226=(\\264e\\032\\351\\2414\\000\\023Px\\000_\\223\\276\\335\\377[\\000\\310\\362\\377\\000\\261\\256\\000\\211\\000\\023\\211\\337\\277\\000\\000\\377\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"\\\\D\\230/\\205\\212\\000l\\371kLp\\277\\260\\005\\030\\255\\021Y\\377\\215\\356\\260\\222csZ\\r\\273Ua\\350\\254\\260\\231F=\\276i\\006\\000s\\naI\\267}\\000\\304\\033\\201>\\377k\\227\\377\\377\\212\\377R{\\377\\377\\377\\377\\366\\200\\220\\373^\\257\\300\\223\\247\\375FRB\\247=*\\226\\370\\013D\\300\\000\\334<b\\320\\327\\037V\\\"\\377K\\332\\260\\000eG\\007N\\215\\017\\201\\324\\000\\377\\377\\000\\257Tm{\\377\\000\\000\\322\\005\\201l\\264\\000\\200\\000\\377\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"M6\\201,\\204m\\032\\243\\312\\227hi\\222\\232\\t\\000\\232\\226\\224\\377~t\\305\\266Gd^\\024\\317IO\\301^\\377\\3127Q\\234\\224\\022\\000\\226er\\204\\205NB\\330\\002,\\267\\211s|\\377|\\306\\377BK\\377\\255\\314o\\223k\\226\\377{m\\377a~\\315\\0248QQ\\000hJ\\316\\202,\\377Z~\\310\\312e\\325.\\'\\236\\020i\\377Ow\\210\\000\\000gc\\t\\233dJ\\377\\276\\000\\306\\267\\206\\000\\323\\220\\000\\352\\000d\\355\\306\\241\\000\\201\\377\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"V7\\231]\\257Zj\\177\\300\\224Wz\\252}\\202Gllz\\377\\177\\177\\264\\253K\\207q\\002\\213BM\\334\\237\\326\\333Rx\\201j>f\\322)\\266`<\\000d\\377Gi\\201\\202\\205c\\217U\\341\\312\\221\\233\\220\\263\\377wH\\2403\\205\\272q\\322v\\312\\313zk\\276\\263\\216\\372\\205\\256\\351\\031\\242$O\\264F\\216\\222E~\\313jD\\233\\036\\014&I\\000\\230j\\266]\\377l\\313\\375\\000\\257y\\266\\000\\2429X_\\000F\\247\\254Q\\000~m\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"=K\\213L\\207\\\"\\241\\233\\236\\203\\226\\237\\377\\203u\\000\\234\\242\\256\\267\\312\\200O[\\251W\\201;\\177w\\033\\304`\\\\\\272c\\377\\013\\2378\\320\\377p\\230bI#/\\310F\\235\\000\\037f\\000\\000\\236\\377X\\360\\377\\352\\227\\225Hd\\363?<\\201\\ti\\272\\377;\\377\\032\\210\\250{\\341bIW\\027\\244[\\240C\\376E\\2039f\\240szdh\\344\\000\\222\\215\\377\\000\\000\\370\\367\\000\\377!sO\\266\\270\\000b\\340[\\000\\000)y\\321<\\000\\305M\"\n",
      "        }\n",
      "      }\n",
      "      feature {\n",
      "        bytes_list {\n",
      "          value: \"5E\\2010m2r\\234\\262\\244|\\264\\377\\260B\\000\\230\\221\\203\\245\\267\\177\\236\\215\\267?\\252u\\211x\\022\\332t\\206\\305l\\367\\r\\276L\\377\\235\\\\\\272Ke:\\000\\237v\\3356\\010]F\\000\\232\\377\\320\\250\\177\\377\\315\\363\\030\\034\\377\\0327&\\000V\\242\\350S\\356\\021\\033S\\027\\257\\030L8\\003\\341\\212um\\272HymCB\\000\\023L\\000\\343\\000\\265q\\377\\000!\\274\\377.\\3772xs\\377\\241\\000\\377\\322\\r\\000\\0004\\\"T<Rny\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: remove google data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification model definition"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:33:10.572334Z",
     "start_time": "2024-07-22T19:33:08.241050Z"
    }
   },
   "source": [
    "from tf_keras import Sequential\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tf_keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "classification_model = Sequential()\n",
    "\n",
    "# adding layers for classification\n",
    "classification_model.add(Conv2D(64, kernel_size=5, strides=1, padding=\"Same\", activation=\"relu\"))\n",
    "classification_model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "classification_model.add(Conv2D(128, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "classification_model.add(MaxPooling2D(padding=\"same\"))\n",
    "classification_model.add(Dropout(0.3))\n",
    "\n",
    "classification_model.add(Flatten())\n",
    "\n",
    "classification_model.add(Dense(256, activation=\"relu\"))\n",
    "classification_model.add(Dropout(0.3))\n",
    "\n",
    "classification_model.add(Dense(512, activation=\"relu\"))\n",
    "classification_model.add(Dropout(0.3))\n",
    "\n",
    "classification_model.add(Dense(len(classes), activation=\"sigmoid\"))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:33:08.685618: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 21:33:08.738918: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 21:33:08.789849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 21:33:08.832429: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 21:33:08.844710: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 21:33:08.930615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 21:33:09.696414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:33:10.587259Z",
     "start_time": "2024-07-22T19:33:10.573155Z"
    }
   },
   "cell_type": "code",
   "source": "classification_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:33:10.590031Z",
     "start_time": "2024-07-22T19:33:10.588274Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model export"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:59:12.530548Z",
     "start_time": "2024-07-22T19:59:12.239976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# adding Googles VGGish model for sound embeddings\n",
    "# TODO: look into licensing\n",
    "vggish = KerasLayer(\"https://www.kaggle.com/models/google/vggish/TensorFlow2/vggish/1\")\n",
    "\n",
    "# adding classification model\n",
    "model = Sequential([\n",
    "    vggish,\n",
    "    classification_model\n",
    "])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile(\"model.tflite\", \"wb\") as file:\n",
    "    file.write(tflite_model)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'keras_layer_8' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(4, 5), dtype=tf.float32, name=None) to TensorSpec(shape=(None,), dtype=tf.float32, name=None)`. Received args: ([[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]],) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_8' (type KerasLayer):\n  • inputs=[['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# adding classification model\u001B[39;00m\n\u001B[1;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m Sequential([\n\u001B[1;32m      9\u001B[0m     vggish,\n\u001B[1;32m     10\u001B[0m     classification_model\n\u001B[1;32m     11\u001B[0m ])\n\u001B[0;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m converter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlite\u001B[38;5;241m.\u001B[39mTFLiteConverter\u001B[38;5;241m.\u001B[39mfrom_keras_model(model)\n\u001B[1;32m     16\u001B[0m tflite_model \u001B[38;5;241m=\u001B[39m converter\u001B[38;5;241m.\u001B[39mconvert()\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow_hub/keras_layer.py:242\u001B[0m, in \u001B[0;36mKerasLayer.call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_training_argument:\n\u001B[0;32m--> 242\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    244\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable:\n",
      "\u001B[0;31mTypeError\u001B[0m: Exception encountered when calling layer 'keras_layer_8' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(4, 5), dtype=tf.float32, name=None) to TensorSpec(shape=(None,), dtype=tf.float32, name=None)`. Received args: ([[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]],) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_8' (type KerasLayer):\n  • inputs=[['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]\n  • training=None"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleeptalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
