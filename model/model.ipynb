{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SleepTalk\n",
    "\n",
    "## Categories:\n",
    "\n",
    "| Category       | Label  |\n",
    "|----------------|--------|\n",
    "| Talk           | SPEECH |\n",
    "| Snoring        | SNORE  |\n",
    "| Sighs          | SIGH   |\n",
    "| Farts          | FART   |\n",
    "| Loud breathing | BREATH |\n",
    "| Cough          | COUGH  |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T22:43:59.384502Z",
     "start_time": "2024-07-21T22:43:59.381962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define classes TODO: define depending on training data\n",
    "\n",
    "classes = [\"SPEECH\", \"SNORE\", \"SIGH\", \"FART\", \"BREATH\", \"COUGH\"]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training data collection\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T22:43:59.390470Z",
     "start_time": "2024-07-21T22:43:59.388067Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model definition"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T22:44:01.541820Z",
     "start_time": "2024-07-21T22:43:59.391432Z"
    }
   },
   "source": [
    "from tf_keras import Sequential\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tf_keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# adding Googles VGGish model for sound embeddings\n",
    "# TODO: look into licensing\n",
    "model.add(KerasLayer(\"https://www.kaggle.com/models/google/vggish/TensorFlow2/vggish/1\"))\n",
    "\n",
    "# adding layers for classification\n",
    "model.add(Conv2D(64, kernel_size=5, strides=1, padding=\"Same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(len(classes), activation=\"sigmoid\"))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:43:59.700846: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 00:43:59.704182: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 00:43:59.712929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 00:43:59.726685: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 00:43:59.730457: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 00:43:59.742298: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 00:44:00.415768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T22:44:01.559101Z",
     "start_time": "2024-07-21T22:44:01.542805Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T22:44:01.562973Z",
     "start_time": "2024-07-21T22:44:01.560634Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model export"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T22:46:38.070693Z",
     "start_time": "2024-07-21T22:46:37.053561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile(\"model.tflite\", \"wb\") as file:\n",
    "    file.write(tflite_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.engine.sequential.Sequential object at 0x79ba03fc2900>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.engine.sequential.Sequential object at 0x79ba03fc2900>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tensorflow_hub.keras_layer.KerasLayer object at 0x79ba03d95c70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tensorflow_hub.keras_layer.KerasLayer object at 0x79ba03d95c70>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x79ba03ce3260>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x79ba03ce3260>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x79ba0666f560>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x79ba0666f560>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x79ba064d1700>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.convolutional.conv2d.Conv2D object at 0x79ba064d1700>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x79ba06629520>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x79ba06629520>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x79ba03c2d3a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x79ba03c2d3a0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.reshaping.flatten.Flatten object at 0x79ba0406df70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.reshaping.flatten.Flatten object at 0x79ba0406df70>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.core.dense.Dense object at 0x79ba029592e0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.core.dense.Dense object at 0x79ba029592e0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x79ba03614470>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x79ba03614470>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.core.dense.Dense object at 0x79ba02959640>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.core.dense.Dense object at 0x79ba02959640>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x79ba02959430>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x79ba02959430>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.core.dense.Dense object at 0x79ba02959040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.core.dense.Dense object at 0x79ba02959040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpla84ry82/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpla84ry82/assets\n",
      "W0000 00:00:1721601997.767834   82900 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1721601997.767853   82900 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-07-22 00:46:37.767977: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpla84ry82\n",
      "2024-07-22 00:46:37.768565: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-07-22 00:46:37.768573: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpla84ry82\n",
      "2024-07-22 00:46:37.773168: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-07-22 00:46:37.935501: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpla84ry82\n",
      "2024-07-22 00:46:37.941469: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 173494 microseconds.\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "Could not translate MLIR to FlatBuffer.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConverterError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      3\u001B[0m converter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlite\u001B[38;5;241m.\u001B[39mTFLiteConverter\u001B[38;5;241m.\u001B[39mfrom_keras_model(model)\n\u001B[0;32m----> 4\u001B[0m tflite_model \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mGFile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel.tflite\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m      7\u001B[0m     file\u001B[38;5;241m.\u001B[39mwrite(tflite_model)\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1231\u001B[0m, in \u001B[0;36m_export_metrics.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1228\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(convert_func)\n\u001B[1;32m   1229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1230\u001B[0m   \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m-> 1231\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_and_export_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1183\u001B[0m, in \u001B[0;36mTFLiteConverterBase._convert_and_export_metrics\u001B[0;34m(self, convert_func, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_conversion_params_metric()\n\u001B[1;32m   1182\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mprocess_time()\n\u001B[0;32m-> 1183\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1184\u001B[0m elapsed_time_ms \u001B[38;5;241m=\u001B[39m (time\u001B[38;5;241m.\u001B[39mprocess_time() \u001B[38;5;241m-\u001B[39m start_time) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[1;32m   1185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1744\u001B[0m, in \u001B[0;36mTFLiteKerasModelConverterV2.convert\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1731\u001B[0m \u001B[38;5;129m@_export_metrics\u001B[39m\n\u001B[1;32m   1732\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1733\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001B[39;00m\n\u001B[1;32m   1734\u001B[0m \n\u001B[1;32m   1735\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;124;03m      Invalid quantization parameters.\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1744\u001B[0m   saved_model_convert_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_as_saved_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1745\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m saved_model_convert_result:\n\u001B[1;32m   1746\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_convert_result\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1725\u001B[0m, in \u001B[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1721\u001B[0m   graph_def, input_tensors, output_tensors \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1722\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_keras_to_saved_model(temp_dir)\n\u001B[1;32m   1723\u001B[0m   )\n\u001B[1;32m   1724\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msaved_model_dir:\n\u001B[0;32m-> 1725\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTFLiteKerasModelConverterV2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1726\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgraph_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_tensors\u001B[49m\n\u001B[1;32m   1727\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1728\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1729\u001B[0m   shutil\u001B[38;5;241m.\u001B[39mrmtree(temp_dir, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1466\u001B[0m, in \u001B[0;36mTFLiteConverterBaseV2.convert\u001B[0;34m(self, graph_def, input_tensors, output_tensors)\u001B[0m\n\u001B[1;32m   1459\u001B[0m   logging\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m   1460\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing new converter: If you encounter a problem \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1461\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease file a bug. You can opt-out \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1462\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mby setting experimental_new_converter=False\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1463\u001B[0m   )\n\u001B[1;32m   1465\u001B[0m \u001B[38;5;66;03m# Converts model.\u001B[39;00m\n\u001B[0;32m-> 1466\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43m_convert_graphdef\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1467\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_def\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1468\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1469\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1470\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconverter_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1471\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1473\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimize_tflite_model(\n\u001B[1;32m   1474\u001B[0m     result,\n\u001B[1;32m   1475\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_quant_mode,\n\u001B[1;32m   1476\u001B[0m     _build_conversion_flags(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconverter_kwargs)\u001B[38;5;241m.\u001B[39mdebug_options,\n\u001B[1;32m   1477\u001B[0m     quant_io\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_new_quantizer,\n\u001B[1;32m   1478\u001B[0m )\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/convert_phase.py:212\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    211\u001B[0m     report_error_message(\u001B[38;5;28mstr\u001B[39m(converter_error))\n\u001B[0;32m--> 212\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m converter_error \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# Re-throws the exception.\u001B[39;00m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    214\u001B[0m   report_error_message(\u001B[38;5;28mstr\u001B[39m(error))\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/convert_phase.py:205\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m ConverterError \u001B[38;5;28;01mas\u001B[39;00m converter_error:\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter_error\u001B[38;5;241m.\u001B[39merrors:\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/convert.py:1014\u001B[0m, in \u001B[0;36mconvert_graphdef\u001B[0;34m(input_data, input_tensors, output_tensors, **kwargs)\u001B[0m\n\u001B[1;32m   1011\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1012\u001B[0m     model_flags\u001B[38;5;241m.\u001B[39moutput_arrays\u001B[38;5;241m.\u001B[39mappend(util\u001B[38;5;241m.\u001B[39mget_tensor_name(output_tensor))\n\u001B[0;32m-> 1014\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_flags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconversion_flags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSerializeToString\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdebug_info_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdebug_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSerializeToString\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdebug_info\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_mlir_converter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_mlir_converter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1020\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow/lite/python/convert.py:376\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001B[0m\n\u001B[1;32m    368\u001B[0m         conversion_flags\u001B[38;5;241m.\u001B[39mguarantee_all_funcs_one_use \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    369\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m convert(\n\u001B[1;32m    370\u001B[0m             model_flags,\n\u001B[1;32m    371\u001B[0m             conversion_flags,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    374\u001B[0m             enable_mlir_converter,\n\u001B[1;32m    375\u001B[0m         )\n\u001B[0;32m--> 376\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converter_error\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _run_deprecated_conversion_binary(\n\u001B[1;32m    379\u001B[0m     model_flags\u001B[38;5;241m.\u001B[39mSerializeToString(),\n\u001B[1;32m    380\u001B[0m     conversion_flags\u001B[38;5;241m.\u001B[39mSerializeToString(),\n\u001B[1;32m    381\u001B[0m     input_data_str,\n\u001B[1;32m    382\u001B[0m     debug_info_str,\n\u001B[1;32m    383\u001B[0m )\n",
      "\u001B[0;31mConverterError\u001B[0m: Could not translate MLIR to FlatBuffer."
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleeptalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
