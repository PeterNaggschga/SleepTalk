{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SleepTalk\n",
    "\n",
    "## Categories:\n",
    "\n",
    "| Category       | Label  |\n",
    "|----------------|--------|\n",
    "| Talk           | SPEECH |\n",
    "| Snoring        | SNORE  |\n",
    "| Sighs          | SIGH   |\n",
    "| Farts          | FART   |\n",
    "| Loud breathing | BREATH |\n",
    "| Cough          | COUGH  |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:21:37.528223Z",
     "start_time": "2024-07-29T15:21:37.525987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define classes TODO: define depending on training data\n",
    "\n",
    "classes = [\"SPEECH\", \"SNORE\", \"SIGH\", \"FART\", \"BREATH\", \"COUGH\"]\n",
    "no_class = \"NONE\""
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training data collection\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:21:24.404321Z",
     "start_time": "2024-07-29T15:21:24.401795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "google_data_dir = \"google\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T15:54:01.903192Z",
     "start_time": "2024-07-28T15:49:56.321819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# download google training embeddings\n",
    "if os.path.exists(google_data_dir):\n",
    "    shutil.rmtree(google_data_dir)\n",
    "    \n",
    "print(\"Downloading training features...\")\n",
    "with urllib.request.urlopen(\"https://storage.googleapis.com/eu_audioset/youtube_corpus/v1/features/features.tar.gz\") as response, tarfile.open(fileobj=response, mode='r|gz') as targz:\n",
    "    targz.extractall(filter='tar')\n",
    "    os.rename(\"audioset_v1_embeddings\", google_data_dir)\n",
    "\n",
    "print(\"done\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:21:31.201435Z",
     "start_time": "2024-07-29T15:21:31.198939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "google_label_file = f\"{google_data_dir}/labels.csv\"\n",
    "if not os.path.exists(google_label_file):\n",
    "    urllib.request.urlretrieve(\"https://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\", google_label_file)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:21:40.556351Z",
     "start_time": "2024-07-29T15:21:40.552992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synonyms = {\n",
    "    classes[0]: [\"Speech\", \"Shout\", \"Whispering\"], # SPEECH\n",
    "    classes[1]: [\"Snoring\"], # SNORE\n",
    "    classes[2]: [\"Sigh\", \"Groan\", \"Grunt\"], # SIGH\n",
    "    classes[3]: [\"Stomach rumble\", \"Fart\"], # FART\n",
    "    classes[4]: [\"Yawn\", \"Sniff\", \"Wheeze\", \"Gasp\", \"Pant\", \"Snort\"], # BREATH\n",
    "    classes[5]: [\"Cough\", \"Sneeze\"], # COUGH\n",
    "    no_class: [\"Chewing, mastication\", \"Biting\", \"Burping, eructation\", \"Bang\", \"Slap, smack\", \"Whack, thwack\", \"Smash, crash\", \"Knock\", \"Tap\", \"Flap\", \"Vehicle\", \"Alarm\", \"Door\", \"Thunderstorm\", \"Wind\", \"Water\", \"Noise\"]\n",
    "}\n",
    "\n",
    "switched_synonyms = {}\n",
    "for (key, entry) in synonyms.items():\n",
    "    for synonym in entry:\n",
    "        switched_synonyms[synonym] = key\n",
    "\n",
    "synonyms = switched_synonyms"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:21:42.591917Z",
     "start_time": "2024-07-29T15:21:42.588574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "label_to_class = {}\n",
    "with open(google_label_file, newline='') as label_file:\n",
    "    reader = csv.reader(label_file)\n",
    "    for row in filter(lambda r: r[2] in synonyms.keys(), reader):\n",
    "        label_to_class[int(row[0])] = synonyms[row[2]]\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:39:48.480809Z",
     "start_time": "2024-07-29T15:39:48.472283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_sequence_examples(filename):\n",
    "    iterator = tf.compat.v1.io.tf_record_iterator(path=filename)\n",
    "    \n",
    "    result = []\n",
    "    for string_record in iterator:\n",
    "        example = tf.train.SequenceExample()\n",
    "        example.ParseFromString(string_record)\n",
    "        result.append(example)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def get_labels(sequence):\n",
    "    return sequence.context.feature[\"labels\"].int64_list.value\n",
    "\n",
    "\n",
    "def get_label_vector(labels: list[int]):\n",
    "    class_names = {label_to_class[label] for label in labels}\n",
    "    label_data = [0 for _ in range(len(classes))]\n",
    "    for class_name in class_names:\n",
    "        if class_name != no_class:\n",
    "            label_data[classes.index(class_name)] = 1\n",
    "    return label_data == [0 for _ in range(len(classes))], label_data\n",
    "    \n",
    "google_embeddings_class = []\n",
    "google_labels_class = []\n",
    "google_embeddings_no_class = []\n",
    "google_labels_no_class = []\n",
    "\n",
    "\n",
    "\n",
    "balanced_train_dir = f\"{google_data_dir}/bal_train\"\n",
    "filenames = [f\"{balanced_train_dir}/{file}\" for file in os.listdir(balanced_train_dir)]\n",
    "\n",
    "for filename in filenames:\n",
    "    for example in get_sequence_examples(filename):\n",
    "        labels = get_labels(example)\n",
    "        if label_to_class.keys().isdisjoint(labels):\n",
    "            continue\n",
    "        no_class, label_vector = get_label_vector(labels)\n",
    "        # TODO: embeddings extrahieren\n",
    "        \n",
    "        if no_class:\n",
    "            google_labels_no_class.append(label_vector)\n",
    "            # TODO google_embeddings_no_class.append(embeddings)\n",
    "        else:\n",
    "            google_labels_class.append(label_vector)\n",
    "            # TODO google_embeddings_class.append(embeddings)\n",
    "        break # TODO: entfernen\n",
    "    break # TODO: entfernen\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True [0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: remove google data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification model definition"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:33:10.572334Z",
     "start_time": "2024-07-22T19:33:08.241050Z"
    }
   },
   "source": [
    "from tf_keras import Sequential\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tf_keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "classification_model = Sequential()\n",
    "\n",
    "# adding layers for classification\n",
    "classification_model.add(Conv2D(64, kernel_size=5, strides=1, padding=\"Same\", activation=\"relu\"))\n",
    "classification_model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "classification_model.add(Conv2D(128, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "classification_model.add(MaxPooling2D(padding=\"same\"))\n",
    "classification_model.add(Dropout(0.3))\n",
    "\n",
    "classification_model.add(Flatten())\n",
    "\n",
    "classification_model.add(Dense(256, activation=\"relu\"))\n",
    "classification_model.add(Dropout(0.3))\n",
    "\n",
    "classification_model.add(Dense(512, activation=\"relu\"))\n",
    "classification_model.add(Dropout(0.3))\n",
    "\n",
    "classification_model.add(Dense(len(classes), activation=\"sigmoid\"))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:33:08.685618: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 21:33:08.738918: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-22 21:33:08.789849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 21:33:08.832429: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 21:33:08.844710: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 21:33:08.930615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 21:33:09.696414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:33:10.587259Z",
     "start_time": "2024-07-22T19:33:10.573155Z"
    }
   },
   "cell_type": "code",
   "source": "classification_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:33:10.590031Z",
     "start_time": "2024-07-22T19:33:10.588274Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model export"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:59:12.530548Z",
     "start_time": "2024-07-22T19:59:12.239976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# adding Googles VGGish model for sound embeddings\n",
    "# TODO: look into licensing\n",
    "vggish = KerasLayer(\"https://www.kaggle.com/models/google/vggish/TensorFlow2/vggish/1\")\n",
    "\n",
    "# adding classification model\n",
    "model = Sequential([\n",
    "    vggish,\n",
    "    classification_model\n",
    "])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile(\"model.tflite\", \"wb\") as file:\n",
    "    file.write(tflite_model)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'keras_layer_8' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(4, 5), dtype=tf.float32, name=None) to TensorSpec(shape=(None,), dtype=tf.float32, name=None)`. Received args: ([[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]],) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_8' (type KerasLayer):\n  • inputs=[['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# adding classification model\u001B[39;00m\n\u001B[1;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m Sequential([\n\u001B[1;32m      9\u001B[0m     vggish,\n\u001B[1;32m     10\u001B[0m     classification_model\n\u001B[1;32m     11\u001B[0m ])\n\u001B[0;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m converter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlite\u001B[38;5;241m.\u001B[39mTFLiteConverter\u001B[38;5;241m.\u001B[39mfrom_keras_model(model)\n\u001B[1;32m     16\u001B[0m tflite_model \u001B[38;5;241m=\u001B[39m converter\u001B[38;5;241m.\u001B[39mconvert()\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow_hub/keras_layer.py:242\u001B[0m, in \u001B[0;36mKerasLayer.call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_training_argument:\n\u001B[0;32m--> 242\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    244\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable:\n",
      "\u001B[0;31mTypeError\u001B[0m: Exception encountered when calling layer 'keras_layer_8' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(4, 5), dtype=tf.float32, name=None) to TensorSpec(shape=(None,), dtype=tf.float32, name=None)`. Received args: ([[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]],) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_8' (type KerasLayer):\n  • inputs=[['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]\n  • training=None"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleeptalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
