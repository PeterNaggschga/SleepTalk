{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SleepTalk\n",
    "\n",
    "## Categories:\n",
    "\n",
    "| Category       | Label  |\n",
    "|----------------|--------|\n",
    "| Talk           | SPEECH |\n",
    "| Snoring        | SNORE  |\n",
    "| Sighs          | SIGH   |\n",
    "| Farts          | FART   |\n",
    "| Loud breathing | BREATH |\n",
    "| Cough          | COUGH  |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:03:55.326009Z",
     "start_time": "2024-08-07T15:03:53.359686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from concurrent.futures import ProcessPoolExecutor as ConcurrentExecutor\n",
    "\n",
    "import tf_keras\n",
    "from tf_keras import Sequential\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tf_keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Input, Rescaling\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 17:03:53.618856: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-07 17:03:53.621712: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-07 17:03:53.629811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-07 17:03:53.642934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-07 17:03:53.646345: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-07 17:03:53.656849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-07 17:03:54.624116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:03:55.329249Z",
     "start_time": "2024-08-07T15:03:55.327102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define classes TODO: define depending on training data\n",
    "\n",
    "classes = [\"SPEECH\", \"SNORE\", \"SIGH\", \"FART\", \"BREATH\", \"COUGH\"]\n",
    "no_class = \"NONE\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training data collection\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:03:56.439549Z",
     "start_time": "2024-08-07T15:03:56.436866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "google_data_dir = \"google\"\n",
    "google_label_file = f\"{google_data_dir}/labels.csv\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:47:34.920138Z",
     "start_time": "2024-08-04T17:43:53.962235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# download google training embeddings\n",
    "if os.path.exists(google_data_dir):\n",
    "    shutil.rmtree(google_data_dir)\n",
    "    \n",
    "print(\"Downloading training features...\")\n",
    "with urllib.request.urlopen(\"https://storage.googleapis.com/eu_audioset/youtube_corpus/v1/features/features.tar.gz\") as response, tarfile.open(fileobj=response, mode='r|gz') as targz:\n",
    "    targz.extractall(filter='tar')\n",
    "    os.rename(\"audioset_v1_embeddings\", google_data_dir)\n",
    "\n",
    "print(\"done\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training features...\n",
      "done\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:04:00.260300Z",
     "start_time": "2024-08-07T15:04:00.257427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# download label file\n",
    "if not os.path.exists(google_label_file):\n",
    "    urllib.request.urlretrieve(\"https://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\", google_label_file)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:04:01.421335Z",
     "start_time": "2024-08-07T15:04:01.417842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synonyms = {\n",
    "    classes[0]: [\"Speech\", \"Shout\", \"Whispering\"], # SPEECH\n",
    "    classes[1]: [\"Snoring\"], # SNORE\n",
    "    classes[2]: [\"Sigh\", \"Groan\", \"Grunt\"], # SIGH\n",
    "    classes[3]: [\"Stomach rumble\", \"Fart\"], # FART\n",
    "    classes[4]: [\"Yawn\", \"Sniff\", \"Wheeze\", \"Gasp\", \"Pant\", \"Snort\"], # BREATH\n",
    "    classes[5]: [\"Cough\", \"Sneeze\"], # COUGH\n",
    "    no_class: [\"Chewing, mastication\", \"Biting\", \"Burping, eructation\", \"Bang\", \"Slap, smack\", \"Whack, thwack\", \"Smash, crash\", \"Knock\", \"Tap\", \"Flap\", \"Vehicle\", \"Alarm\", \"Door\", \"Thunderstorm\", \"Wind\", \"Water\", \"Noise\"]\n",
    "}\n",
    "\n",
    "switched_synonyms = {}\n",
    "for (key, entry) in synonyms.items():\n",
    "    for synonym in entry:\n",
    "        switched_synonyms[synonym] = key\n",
    "\n",
    "synonyms = switched_synonyms"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:04:02.624699Z",
     "start_time": "2024-08-07T15:04:02.620876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_to_class = {}\n",
    "with open(google_label_file, newline='') as label_file:\n",
    "    reader = csv.reader(label_file)\n",
    "    for row in filter(lambda r: r[2] in synonyms.keys(), reader):\n",
    "        label_to_class[int(row[0])] = synonyms[row[2]]\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:11:31.987692Z",
     "start_time": "2024-08-07T15:11:26.399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sequence_examples(filename):\n",
    "    return [tf.train.SequenceExample.FromString(record.numpy()) for record in tf.data.TFRecordDataset(filename)]\n",
    "\n",
    "\n",
    "def get_labels(sequence):\n",
    "    return sequence.context.feature[\"labels\"].int64_list.value\n",
    "\n",
    "\n",
    "def get_label_vector(labels: list[int]):\n",
    "    class_names = {label_to_class[label] for label in labels if label in label_to_class.keys()}\n",
    "    label_data = [0 for _ in range(len(classes))]\n",
    "    for class_name in class_names:\n",
    "        if class_name != no_class:\n",
    "            label_data[classes.index(class_name)] = 1\n",
    "    return np.array(label_data)\n",
    "\n",
    "\n",
    "def get_embeddings(sequence):\n",
    "    result = []\n",
    "    for feature in sequence.feature_lists.feature_list[\"audio_embedding\"].feature:\n",
    "        byte_list = feature.bytes_list.value[0]\n",
    "        byte_list = tf.io.decode_raw(byte_list, tf.uint8).numpy()\n",
    "        byte_list = tf.cast(byte_list, tf.float32).numpy()\n",
    "        result.append(byte_list / 2 ** 7 - 1)\n",
    "    return np.array(result)\n",
    "\n",
    "def get_file_content(filename):\n",
    "    with_class = []\n",
    "    without_class = []\n",
    "    for example in get_sequence_examples(filename):\n",
    "        labels = get_labels(example)\n",
    "        if label_to_class.keys().isdisjoint(labels):\n",
    "            continue\n",
    "        label_vector = get_label_vector(labels)\n",
    "        embeddings = get_embeddings(example)\n",
    "        if max(label_vector) != 0:\n",
    "            with_class.append((embeddings, label_vector))\n",
    "        else:\n",
    "            without_class.append((embeddings, label_vector))\n",
    "    return with_class, without_class\n",
    "\n",
    "balanced_train_dir = f\"{google_data_dir}/unbal_train\"\n",
    "filenames = [f\"{balanced_train_dir}/{file}\" for file in os.listdir(balanced_train_dir)]\n",
    "\n",
    "# TODO: Warnungen unterdr√ºcken \n",
    "\n",
    "print(\"Reading google data...\")\n",
    "with ConcurrentExecutor() as pool:\n",
    "    intermediate_results = pool.map(get_file_content, filenames)\n",
    "print(\"done\")\n",
    "print(\"Accumulating...\")\n",
    "google_class, google_no_class = reduce(lambda a, b: (a[0] + b[0], a[1] + b[1]), list(intermediate_results))\n",
    "print(\"done\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "Reading google data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 17:11:29.787532: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.789843: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.790056: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.790809: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.793927: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.800451: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.804177: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.810926: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.812808: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.814091: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.816850: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.817407: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.823296: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.853328: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.853589: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-07 17:11:29.854967: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 50\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(get_file_content(filenames[\u001B[38;5;241m0\u001B[39m])[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmin())\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReading google data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 50\u001B[0m \u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mConcurrentExecutor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpool\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintermediate_results\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_file_content\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/concurrent/futures/_base.py:647\u001B[0m, in \u001B[0;36mExecutor.__exit__\u001B[0;34m(self, exc_type, exc_val, exc_tb)\u001B[0m\n\u001B[1;32m    646\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type, exc_val, exc_tb):\n\u001B[0;32m--> 647\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwait\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    648\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/concurrent/futures/process.py:873\u001B[0m, in \u001B[0;36mProcessPoolExecutor.shutdown\u001B[0;34m(self, wait, cancel_futures)\u001B[0m\n\u001B[1;32m    870\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_executor_manager_thread_wakeup\u001B[38;5;241m.\u001B[39mwakeup()\n\u001B[1;32m    872\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_executor_manager_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m wait:\n\u001B[0;32m--> 873\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_executor_manager_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001B[39;00m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;66;03m# objects that use file descriptors.\u001B[39;00m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_executor_manager_thread \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/threading.py:1147\u001B[0m, in \u001B[0;36mThread.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[1;32m   1150\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[1;32m   1151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/threading.py:1167\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1168\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:00.957264Z",
     "start_time": "2024-08-07T14:32:00.794048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.shuffle(google_class)\n",
    "np.random.shuffle(google_no_class)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:32:02.113039Z",
     "start_time": "2024-08-07T14:32:00.958011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_len = min(len(google_class), len(google_no_class))\n",
    "google_class = google_class[:min_len]\n",
    "google_no_class = google_no_class[:min_len]    "
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:33:47.719003Z",
     "start_time": "2024-08-07T14:32:02.114779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_ragged(tensors):\n",
    "    return tf.ragged.constant(tensors, ragged_rank=1)\n",
    "\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return [a[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)] for i in range(n)]\n",
    "\n",
    "\n",
    "training_embeddings, training_labels = zip(*[x for y in zip(google_class, google_no_class) for x in y])\n",
    "print(\"Creating input tensors...\")\n",
    "with ConcurrentExecutor() as pool:\n",
    "    training_embeddings = pool.map(to_ragged, split(training_embeddings, 32))\n",
    "training_embeddings = tf.concat(list(training_embeddings), axis=0).to_tensor()\n",
    "training_labels = tf.constant(training_labels)\n",
    "print(\"done\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input tensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 16:33:46.153577: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1050139136 exceeds 10% of free system memory.\n",
      "2024-08-07 16:33:46.610940: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1055979520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T09:15:19.017898Z",
     "start_time": "2024-08-06T09:15:19.015331Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO: remove google data",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification model definition"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:33:47.725051Z",
     "start_time": "2024-08-07T14:33:47.720093Z"
    }
   },
   "source": [
    "def get_classifier(weights=None):\n",
    "    result = Sequential()\n",
    "    \n",
    "    result.add(Input(shape=(None, 128), dtype=tf.float32))\n",
    "    \n",
    "    # adding layers for classification\n",
    "    result.add(Conv1D(64, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\", data_format=\"channels_last\"))\n",
    "    result.add(MaxPooling1D(padding=\"same\", data_format=\"channels_last\"))\n",
    "    result.add(Dropout(0.3))\n",
    "    \n",
    "    result.add(Conv1D(128, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\", data_format=\"channels_last\"))\n",
    "    result.add(GlobalMaxPooling1D(data_format=\"channels_last\"))\n",
    "    result.add(Dropout(0.3))\n",
    "    \n",
    "    result.add(Dense(256, activation=\"relu\"))\n",
    "    result.add(Dropout(0.3))\n",
    "    \n",
    "    result.add(Dense(512, activation=\"relu\"))\n",
    "    result.add(Dropout(0.3))\n",
    "    \n",
    "    result.add(Dense(len(classes), activation=\"sigmoid\"))\n",
    "    \n",
    "    if weights is not None:\n",
    "        result.set_weights(weights)\n",
    "\n",
    "    result.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:34:43.700754Z",
     "start_time": "2024-08-07T14:34:43.536108Z"
    }
   },
   "cell_type": "code",
   "source": "classification_model = get_classifier()",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model training"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T14:39:27.103199Z",
     "start_time": "2024-08-07T14:34:46.364162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "early_stop = tf_keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "classification_model.fit(training_embeddings, training_labels, batch_size=32, validation_split=.15, shuffle=True, epochs=30, callbacks=[early_stop])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5479/5479 [==============================] - 19s 3ms/step - loss: 0.0527 - accuracy: 0.9976 - val_loss: 0.0464 - val_accuracy: 0.9983\n",
      "Epoch 2/30\n",
      "5479/5479 [==============================] - 18s 3ms/step - loss: 0.0471 - accuracy: 0.9978 - val_loss: 0.0482 - val_accuracy: 0.9983\n",
      "Epoch 3/30\n",
      "5479/5479 [==============================] - 24s 4ms/step - loss: 0.0460 - accuracy: 0.9978 - val_loss: 0.0492 - val_accuracy: 0.9983\n",
      "Epoch 4/30\n",
      "5479/5479 [==============================] - 19s 3ms/step - loss: 0.0457 - accuracy: 0.9978 - val_loss: 0.0434 - val_accuracy: 0.9983\n",
      "Epoch 5/30\n",
      "5479/5479 [==============================] - 18s 3ms/step - loss: 0.0448 - accuracy: 0.9978 - val_loss: 0.0474 - val_accuracy: 0.9983\n",
      "Epoch 6/30\n",
      "5479/5479 [==============================] - 18s 3ms/step - loss: 0.0453 - accuracy: 0.9978 - val_loss: 0.0436 - val_accuracy: 0.9983\n",
      "Epoch 7/30\n",
      "5479/5479 [==============================] - 18s 3ms/step - loss: 0.0456 - accuracy: 0.9978 - val_loss: 0.0432 - val_accuracy: 0.9983\n",
      "Epoch 8/30\n",
      "5479/5479 [==============================] - 26s 5ms/step - loss: 0.0454 - accuracy: 0.9978 - val_loss: 0.0442 - val_accuracy: 0.9983\n",
      "Epoch 9/30\n",
      "5479/5479 [==============================] - 41s 8ms/step - loss: 0.0455 - accuracy: 0.9978 - val_loss: 0.0452 - val_accuracy: 0.9983\n",
      "Epoch 10/30\n",
      "5479/5479 [==============================] - 28s 5ms/step - loss: 0.0452 - accuracy: 0.9978 - val_loss: 0.0472 - val_accuracy: 0.9983\n",
      "Epoch 11/30\n",
      "5479/5479 [==============================] - 27s 5ms/step - loss: 0.0501 - accuracy: 0.9978 - val_loss: 0.0444 - val_accuracy: 0.9983\n",
      "Epoch 12/30\n",
      "5479/5479 [==============================] - 25s 5ms/step - loss: 0.0453 - accuracy: 0.9978 - val_loss: 0.0441 - val_accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x70b683271df0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model export"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T15:06:47.454752Z",
     "start_time": "2024-08-07T15:06:47.209140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# downloading Googles VGGish model for sound embeddings\n",
    "# TODO: look into licensing\n",
    "vggish = KerasLayer(\"https://www.kaggle.com/models/google/vggish/TensorFlow2/vggish/1\")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T19:59:12.530548Z",
     "start_time": "2024-07-22T19:59:12.239976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# adding classification model\n",
    "model = Sequential([\n",
    "    vggish,\n",
    "    classification_model\n",
    "])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile(\"model.tflite\", \"wb\") as file:\n",
    "    file.write(tflite_model)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'keras_layer_8' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(4, 5), dtype=tf.float32, name=None) to TensorSpec(shape=(None,), dtype=tf.float32, name=None)`. Received args: ([[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]],) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_8' (type KerasLayer):\n  ‚Ä¢ inputs=[['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]\n  ‚Ä¢ training=None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# adding classification model\u001B[39;00m\n\u001B[1;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m Sequential([\n\u001B[1;32m      9\u001B[0m     vggish,\n\u001B[1;32m     10\u001B[0m     classification_model\n\u001B[1;32m     11\u001B[0m ])\n\u001B[0;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m converter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlite\u001B[38;5;241m.\u001B[39mTFLiteConverter\u001B[38;5;241m.\u001B[39mfrom_keras_model(model)\n\u001B[1;32m     16\u001B[0m tflite_model \u001B[38;5;241m=\u001B[39m converter\u001B[38;5;241m.\u001B[39mconvert()\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/src/miniforge3/envs/sleeptalk/lib/python3.12/site-packages/tensorflow_hub/keras_layer.py:242\u001B[0m, in \u001B[0;36mKerasLayer.call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_training_argument:\n\u001B[0;32m--> 242\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    244\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable:\n",
      "\u001B[0;31mTypeError\u001B[0m: Exception encountered when calling layer 'keras_layer_8' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(4, 5), dtype=tf.float32, name=None) to TensorSpec(shape=(None,), dtype=tf.float32, name=None)`. Received args: ([[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]],) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_8' (type KerasLayer):\n  ‚Ä¢ inputs=[['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)'], ['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(), dtype=float32)']]\n  ‚Ä¢ training=None"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleeptalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
